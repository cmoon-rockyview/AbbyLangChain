{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('AbbyUtils.py')\n",
    "from AbbyUtils import langsmith\n",
    "langsmith('AbbyCh03', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ChatPromptTemplate` can be used when you want to inject a list of conversations as a prompt.\n",
    "\n",
    "Messages are composed in tuple format, (`role`, `message`), and created as a list.\n",
    "\n",
    "**role**\n",
    "- `\"system\"`: System setting message. Mainly prompts related to global settings.\n",
    "- `\"human\"`: User input message.\n",
    "- `\"ai\"`: AI response message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, load_prompt\n",
    "\n",
    "# ChatPromptTemplate 생성\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"user\", \"Where is capital of {country}\"),\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"Where is captial of {country}\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt.format(country=\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"You are a friendly AI assistant. Your name is {name}.\"),\n",
    "        (\"human\", \"Nice to meet you!\"),\n",
    "        (\"ai\", \"Hello! How can I assist you?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 챗 message 를 생성합니다.\n",
    "messages = chat_template.format_messages(\n",
    "    name=\"Chris\", user_input=\"What is your name?\"\n",
    ")\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "prompt_langsmith = client.pull_prompt(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptAbby = client.pull_prompt(\"abby_cc01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promptAbby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = promptAbby.template\n",
    "print(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"abby_cc01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"chmoon/abby_cc01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are analyzing an email from the council correspondence of the City of Abbotsford, BC. \n",
      "  Your task is to categorize the {email_content} into one of the following predefined categories:\n",
      "\n",
      "  1. **Legal & Legislative Services**\n",
      "  2. **Abbotsford Police Department**\n",
      "  3. **Innovation, Strategy & Intergovernmental Relations**\n",
      "  4. **Planning & Development Services**\n",
      "  5. **Engineering**\n",
      "  6. **Finance & Procurement Services**\n",
      "  7. **Airport**\n",
      "  8. **Parks, Recreation & Culture**\n",
      "  9. **Operations**\n",
      "  10. **Fire Rescue Services**\n",
      "\n",
      "  ### Instructions:\n",
      "\n",
      "  - Carefully read the email content.\n",
      "  - Analyze its main subject matter and context.\n",
      "  - Determine which category best represents the topic of the email.\n",
      "  - If more than two categories are required, list each category along with its respective score.\n",
      "  - Think through the classification process step by step before making a final decision.\n",
      "\n",
      "  Format:\n",
      "  {format}\n"
     ]
    }
   ],
   "source": [
    "print(prompt.template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
