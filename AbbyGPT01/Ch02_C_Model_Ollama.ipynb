{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' Abbotsford is a city in the province of British Columbia, Canada. It is located in the lower Fraser Valley region and is situated on the Fraser River and its mission tributary, approximately 65 kilometers (40 mi) east of Vancouver. The city has a population of around 150,000 people as of 2021. Abbotsford is known for its agriculture industry, especially the production of blueberries, raspberries, and sweet corn. It also has a significant cultural and recreational center in the Fraser Valley region, hosting various events such as the annual Abbotsford International Airshow.' response_metadata={'model': 'mistral', 'created_at': '2025-02-17T06:01:34.0976607Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 34747852500, 'load_duration': 11737613300, 'prompt_eval_count': 13, 'prompt_eval_duration': 1267000000, 'eval_count': 137, 'eval_duration': 21736000000} id='run-38a30760-df3e-478a-9a68-d70305dedd9d-0'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"mistral\")\n",
    "response = llm.invoke(\"Where is abbotsford located?\")\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abbotsford is a city in the province of British Columbia, Canada. It's situated in the lower Fraser Valley region, approximately 65 kilometers (40 miles) east of Vancouver. The city is known for its beautiful scenery, agricultural land, and the scenic Fraser River, which flows through it. Abbotsford is also home to the University of the Fraser Valley and the Abbotsford International Airport."
     ]
    }
   ],
   "source": [
    "answer = llm.stream(\"Where is abbotsford located?\")\n",
    "\n",
    "final_answer = ''\n",
    "for token in answer:\n",
    "    final_answer += token.content\n",
    "    print(token.content, end=\"\", flush=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/Administrator/AppData/Local/nomic.ai/GPT4All/Llama-3.2-1B-Instruct-Q4_0.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import GPT4All\n",
    "import os\n",
    "\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "    print(\"✅ Model file found!\")\n",
    "    llm = GPT4All(model=model_path, backend = \"cpu\")\n",
    "    response = llm.invoke(\"Where is Abbotsford?\")\n",
    "    print(response)\n",
    "else:\n",
    "    print(\"❌ Model file NOT found! Check the path again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"mixtral-8x7b-32768\",  # Specify the model name\n",
    "    #model = \"deepseek-r1-distill-qwen-32b\",\n",
    "    temperature=0,             # Set the desired temperature\n",
    "    max_tokens= 1024,              # Define the maximum number of tokens\n",
    "    # Additional parameters as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are such a good assistant!\"),\n",
    "    (\"human\", \"{input_text}\"),\n",
    "                # Define the maximum number of tokens\n",
    "])\n",
    "\n",
    "# Combine the prompt with the model\n",
    "chain = prompt | llm\n",
    "\n",
    "# Generate a response\n",
    "response = chain.invoke({\"input_text\": \"Tell me about abbotsford\"})\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
