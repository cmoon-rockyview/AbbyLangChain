{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "\n",
    "sys.path.append('AbbyUtils.py')\n",
    "\n",
    "#API Key Load\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AbbyUtils import langsmith\n",
    "langsmith('AbbyCh02', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langsmith(\"AbbyCh02\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    temperature= 1,\n",
    "    model = \"gpt-4o-mini\",\n",
    "    max_tokens= 1000\n",
    ")\n",
    "\n",
    "question = \"What is the meaning of life in 100 words?\"\n",
    "\n",
    "response = llm.invoke(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: https://platform.openai.com/docs/models\n",
    "\n",
    "Price: https://platform.openai.com/docs/pricing\n",
    "\n",
    "Context Windows: https://zapier.com/blog/context-window/\n",
    "\n",
    "OpenAI GPT API Pricing Calculator : https://gptforwork.com/tools/openai-chatgpt-api-pricing-calculator\n",
    "\n",
    "Tiktokenizer : https://tiktokenizer.vercel.app/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_logprob = ChatOpenAI(\n",
    "    temperature=0.1,  # Creativity (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # Max Tokens\n",
    "    model_name=\"gpt-4o-mini\",  # Model\n",
    ").bind(logprobs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = \"Tell me about the city of Abbotsford in 100 words\"\n",
    "\n",
    "\n",
    "response = llm_with_logprob.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.response_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.invoke(\"List the top 5 places in the city of Abbotsford\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm.stream(\"List the top 5 places in the city of Abbotsford\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer = ''\n",
    "for token in answer:\n",
    "    final_answer += token.content\n",
    "    print(token.content, end=\"\", flush=True)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AbbyUtils import stream_response\n",
    "\n",
    "answer = llm.stream(\"List the top 5 places in the city of Abbotsford\")\n",
    "final_answer = stream_response(answer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to track token usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = llm.invoke (\"Tell me about the city of Abbotsford in 100 words\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$0.0000786"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"Tell me about the city of Abbotsford in 100 words\")\n",
    "    print(f\"Total Token: \\t\\t{cb.total_tokens}\")\n",
    "    print(f\"prompt token: \\t{cb.prompt_tokens}\")\n",
    "    print(f\"completion token: \\t{cb.completion_tokens}\")\n",
    "    print(f\"Cost(USD): \\t${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AbbyUtils import MultiModal\n",
    "from AbbyUtils import stream_response\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "multimodal_llm = MultiModal(llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URL = \"../images/Sign.jpg\"\n",
    "answer = multimodal_llm.stream(IMAGE_URL)\n",
    "stream_response(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a poet. Your task is to write a poem with the given image\"\n",
    "user_prompt = \"Write a poem about the image below\"\n",
    "multimodal_llm = MultiModal(llm, system_prompt=system_prompt, user_prompt=user_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_PATH_FROM_FILE = \"../images/Sign.jpg\"\n",
    "answer = multimodal_llm.stream(IMAGE_PATH_FROM_FILE)\n",
    "stream_response(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
